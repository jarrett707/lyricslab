{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOINaQvafR+hQyxh0NeHQTH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarrett707/lyricslab/blob/main/LyricsLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9LFCTpplMb0",
        "outputId": "fda69e15-8e57-4f0e-bb6d-ffa2a858d625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Lyrics-Generation-using-RNNs'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 58 (delta 27), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (58/58), 134.68 KiB | 2.64 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PratikSaha198/Lyrics-Generation-using-RNNs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "4pqFdKuoDeyT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = 'lyrics_dataset.txt'"
      ],
      "metadata": {
        "id": "rOG1c3h3Dmzi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opening the text file in read mode and standard encoding it\n",
        "text = open('spotify_millsongdata.csv', 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# Length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mbj5hmZDwAH",
        "outputId": "afe62caa-2ac7-4b45-bd09-13fbb0631f20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 3145728 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A look at the first 250 characters in text\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5roBU8KbDxVn",
        "outputId": "b5bbc8c7-3242-4a2c-ac57-25ecb51b2957"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "artist,song,link,text\r\n",
            "ABBA,Ahe's My Kind Of Girl,/a/abba/ahes+my+kind+of+girl_20598417.html,\"Look a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlmj_mRzD0vc",
        "outputId": "35b2d1af-f2bc-4d3c-d54b-e5486d09027c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "metadata": {
        "id": "gycg6kXbD3Q4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('{ ===========>')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n==========>}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeFPP8R7D-Nf",
        "outputId": "c13a51c7-9a81-442c-b8f9-6c4a889d4e87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ ===========>\n",
            "  '\\n':   0,\n",
            "  '\\r':   1,\n",
            "  ' ' :   2,\n",
            "  '!' :   3,\n",
            "  '\"' :   4,\n",
            "  \"'\" :   5,\n",
            "  '(' :   6,\n",
            "  ')' :   7,\n",
            "  '+' :   8,\n",
            "  ',' :   9,\n",
            "  '-' :  10,\n",
            "  '.' :  11,\n",
            "  '/' :  12,\n",
            "  '0' :  13,\n",
            "  '1' :  14,\n",
            "  '2' :  15,\n",
            "  '3' :  16,\n",
            "  '4' :  17,\n",
            "  '5' :  18,\n",
            "  '6' :  19,\n",
            "  ...\n",
            "==========>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show how the first 20 characters from the text are mapped to integers\n",
        "print ('{} ==> characters mapped to int ==> {}'.format(repr(text[:20]), text_as_int[:20]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICyj2HqAEB0f",
        "outputId": "aba77b93-bb54-49d5-93cb-f676fd98aa81"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'artist,song,link,tex' ==> characters mapped to int ==> [54 71 73 62 72 73  9 72 68 67 60  9 65 62 67 64  9 73 58 77]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()] , end = \"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USEKGOyUEHRD",
        "outputId": "eb14a9e2-278a-489d-9d23-edc812658360"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "artis"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using batch method converted individual characters to sequences of desired size\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR8ia3r9ELEf",
        "outputId": "36a710df-565c-4493-a890-c81e67d689ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'artist,song,link,text\\r\\nABBA,Ahe\\'s My Kind Of Girl,/a/abba/ahes+my+kind+of+girl_20598417.html,\"Look at'\n",
            "\" her face, it's a wonderful face  \\r\\nAnd it means something special to me  \\r\\nLook at the way that she \"\n",
            "\"smiles when she sees me  \\r\\nHow lucky can one fellow be?  \\r\\n  \\r\\nShe's just my kind of girl, she makes \"\n",
            "\"me feel fine  \\r\\nWho could ever believe that she could be mine?  \\r\\nShe's just my kind of girl, without\"\n",
            "\" her I'm blue  \\r\\nAnd if she ever leaves me what could I do, what could I do?  \\r\\n  \\r\\nAnd when we go fo\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "Zf3N7sfgEPTn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_YYwgFtERrr",
        "outputId": "a2ed678c-3878-441e-c5d2-82fc428fd638"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  'artist,song,link,text\\r\\nABBA,Ahe\\'s My Kind Of Girl,/a/abba/ahes+my+kind+of+girl_20598417.html,\"Look a'\n",
            "Target data: 'rtist,song,link,text\\r\\nABBA,Ahe\\'s My Kind Of Girl,/a/abba/ahes+my+kind+of+girl_20598417.html,\"Look at'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYWOto1nEUyx",
        "outputId": "820e9756-b54d-4dae-abfe-3e1efbb608a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1500 # keep between (1024 -> 1800) for best results"
      ],
      "metadata": {
        "id": "oO0gWd1lEVf_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "    tf.keras.layers.Dense(vocab_size,activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "cOD6qVxKEZQf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "JEV2sudkEcKu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_1HWjULEheD",
        "outputId": "2b2d0d03-4e40-4d17-a59b-085cf58d4fe7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 80) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsZpSJI5EkCu",
        "outputId": "3b9e8434-c3c6-42f3-a84c-473be08cf7f2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           20480     \n",
            "                                                                 \n",
            " gru (GRU)                   (64, None, 1500)          7911000   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 80)            120080    \n",
            "                                                                 \n",
            " dropout (Dropout)           (64, None, 80)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8051560 (30.71 MB)\n",
            "Trainable params: 8051560 (30.71 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVpvxHUXEnrP",
        "outputId": "09426640-29c6-4645-c768-9f7236260add"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22, 64, 24, 17, 45, 50, 75, 32, 72, 11, 57, 40, 17, 79,  2, 64, 39,\n",
              "       55, 23, 76, 53, 72,  7, 19, 75,  8, 56, 33, 48, 53, 17, 11, 42, 26,\n",
              "       76, 11, 69, 36,  3, 60, 46, 28, 20, 50, 48, 53, 74, 15, 71, 29, 27,\n",
              "       64, 47, 36,  6, 16, 56, 24, 47, 73, 16, 69, 51, 41, 16, 57, 15, 15,\n",
              "       19, 56, 54, 69, 49, 73, 53,  2, 71, 36, 41, 41, 57, 25, 41,  1,  8,\n",
              "       19, 67, 49, 43, 29, 29, 60, 67, 31, 42,  5, 26, 79, 26, 44])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJonCe1PEq5t",
        "outputId": "9705e114-35e1-4308-8c73-deec2018857a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            " 'st a state of mind  \\r\\nAnd who knows what it is that we might find  \\r\\nIf we try  \\r\\nAnd who knows what'\n",
            "\n",
            "Next Char Predictions: \n",
            " \"9k?4UZvHs.dP4z kOb:w_s)6v+cIX_4.RBw.pL!gVD7ZX_u2rECkWL(3c?Wt3p[Q3d226capYt_ rLQQdAQ\\r+6nYSEEgnGR'BzBT\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c2O2SB3EvNf",
        "outputId": "1525d5fc-65a1-42e1-abfb-15031d75b58e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 80)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.3823156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "8TWcSc_iExfa"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "MhoOfroqEz1b"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "metadata": {
        "id": "UO2RVNpfE8BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "eObtMyttFB_n"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLzyX82OFD-s",
        "outputId": "e4f15d7f-3595-4a83-a3f1-956408bef3bd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 256)            20480     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (1, None, 1500)           7911000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 80)             120080    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (1, None, 80)             0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8051560 (30.71 MB)\n",
            "Trainable params: 8051560 (30.71 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_text(model, chars_to_generate , temp , start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = chars_to_generate\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = temp\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "Z5E3j_36FEmR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import arange\n",
        "\n",
        "# Number of characters to generate (keep between 250 to 500)\n",
        "chars_to_generate = 500\n",
        "\n",
        "# Printing the generated text\n",
        "# Temperature 1.0 gives the craziest output and 0.1 gives the lowest varience\n",
        "# Keeping the temperature 0.35 gives best meaningful / coherent text.\n",
        "\n",
        "# Give the seed string as the first word of generate text\n",
        "print(generate_text(model , chars_to_generate , 0.35 , start_string=u\"Hate \"))\n",
        "\n",
        "# Uncomment below to check the variences ==>\n",
        "\n",
        "# for i in arange(0.1,1.1,0.1):\n",
        "#   print(\"==============\")\n",
        "#   print(\"FOR TEMP : {} \".format(i))\n",
        "#   print(\"==============\")\n",
        "#   print(generate_text(model , chars_to_generate , i , start_string=u\"Love \"))\n",
        "#   print()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFJgIZcWFI_P",
        "outputId": "b0c34fd6-0540-4af6-a97a-2671e4041a59"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hate and me  \r\n",
            "And a real your brade  \r\n",
            "And you be a love  \r\n",
            "And when you want to live  \r\n",
            "1way you are in you  \r\n",
            "  \r\n",
            "And when you're not can!  \r\n",
            "  \r\n",
            "And chance was to be the start  \r\n",
            "  \r\n",
            "And the way you love me  \r\n",
            "  \r\n",
            "And the eas  \r\n",
            "And then you want to be a broke  \r\n",
            "  \r\n",
            "And it's a man  \r\n",
            "And when you to be back to me  \r\n",
            "And when you be a shere  \r\n",
            "And when you're not the beat  \r\n",
            "  \r\n",
            "And she's a start and the say  \r\n",
            "And the sing and show the start  \r\n",
            "  \r\n",
            "So you be the say  \r\n",
            "And you're hard to say  \r\n",
            "\n"
          ]
        }
      ]
    }
  ]
}